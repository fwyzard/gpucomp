<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Stefan Rua" />
  <title>Exploration of GPU-enabled lossless compressors</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Exploration of GPU-enabled lossless compressors</h1>
<p class="author">Stefan Rua</p>
</header>
<p><code>stefan.elias.rua@cern.ch</code><br />
<!--`stefan.rua@aalto.fi` \--> <code>stefan.rua@iki.fi</code></p>
<p>We present the results of a study on the use of GPUs for data compression, using collision data collected by the CMS experiment as a case study.</p>
<!--
![](results/combined-pp-nolegend.png){ width=80% } \

* = GPU \
** = NX \
-->
<h1 id="background">Background</h1>
<p>The Compact Muon Solenoid (CMS) is a detector and an experiment at CERN. It gathers data on collisions taking place in the Large Hadron Collider (LHC). Not all of the data contains interesting events, and it goes through multiple levels of triggers where most of it is discarded. The last trigger is the High Level Trigger (HLT), from which the data is sent to datacenters away from the detector. In order to speed up the network transfers between the HLT and datacenters, the data is compressed.</p>
<h1 id="motivation">Motivation</h1>
<p>Currently the data is compressed using CPUs which are used for other workloads as well. The machines at the HLT are equipped with GPUs, so it would be good to reduce CPU time taken by the compression workload by transferring it onto the GPUs. <!--GPUs can also be very fast.--></p>
<!--
# What I did

- Looked for GPU compressor implementations
- Added them to a benchmarking program
- Compared them to CPU compressors
-->
<h1 id="benchmarking">Benchmarking</h1>
<p>We implemented the compressors into a benchmarking program called <code>lzbench</code>. When possible, compressors are compiled with the same compiler options to achieve the fairest possible comparison. <code>lzbench</code> runs the compression in memory, meaning that disk reads and writes are excluded.</p>
<p>The benchmarks were run on two machines, one that resembles the machines in the HLT and a POWER9 machine. The HLT doesn’t have POWER9 machines, but we wanted to investigate <code>libnxz</code>, a zlib-compatible library that makes use of the NX GZIP hardware accelerator present on the POWER9 chip.</p>
<h2 id="compressors">Compressors</h2>
<!--
| Name | Description |
|:---|:---|
| `bsc`[^bsc] | **B**lock-**s**orting **c**ompressor by Ilya Grebnov. |
| `dietgpu`[^dietgpu] | Asymmetric numeral systems (ANS)[^ans] implementation by Facebook. |
| `libxz`[^libnxz]^,^[^libnxz_git] | IBM's POWER9 processors have a hardware accelerator, NX, for `gzip`. `libnxz` is the library for compressing on it. |
| `nvcomp`[^nvcomp]^,^[^nvcomp_git] | Compression library by Nvidia, unfortunately made proprietary in version 2.3. |
-->
<p>Following is a list of the compressors we benchmarked. Links to their source code be found in the “Links” section.</p>
<ul>
<li><code>bsc</code><br />
Block-sorting compressor by Ilya Grebnov.<br />
</li>
<li><code>dietgpu</code><br />
Asymmetric numeral systems (ANS) implementation by Facebook.<br />
</li>
<li><code>libxz</code><br />
IBM’s POWER9 processors have a hardware accelerator for <code>gzip</code> called NX. <code>libnxz</code> is the library for compressing on it.<br />
</li>
<li><code>nvcomp</code><br />
Compression library by Nvidia, unfortunately made proprietary in version 2.3. We tested the earlier open source version which was already in <code>lzbench</code>.</li>
</ul>
<!--
- `bsc`[^bsc] \
**B**lock-**s**orting **c**ompressor by Ilya Grebnov. \
- `dietgpu`[^dietgpu] \
Asymmetric numeral systems (ANS)[^ans] implementation by Facebook. \
- `libxz`[^libnxz]^,^[^libnxz_git] \
IBM's POWER9 processors have a hardware accelerator, NX, for `gzip`. `libnxz` is the library for compressing on it. \
- `nvcomp`[^nvcomp]^,^[^nvcomp_git] \
Compression library by Nvidia, unfortunately made proprietary in version 2.3.


[^bsc]: <https://github.com/IlyaGrebnov/libbsc>
[^ans]: <https://arxiv.org/pdf/1311.2540.pdf>
[^dietgpu]: <https://github.com/facebookresearch/dietgpu>
[^libnxz]: <https://dl.acm.org/doi/pdf/10.1109/ISCA45697.2020.00012>
[^libnxz_git]: <https://github.com/libnxz/power-gzip>
[^nvcomp]: <https://developer.nvidia.com/nvcomp>
[^nvcomp_git]: <https://github.com/NVIDIA/nvcomp>
-->
<h2 id="data">Data</h2>
<p>Two types of collisions take place at the LHC: proton-proton and heavy ion collisions. We ran the benchmarks on both types of data.</p>
<h3 id="proton-proton-events">Proton-proton events</h3>
<!--
- HadronsTaus stream from 2022
- pileup $\approx$ 50
-->
<ul>
<li>100 files</li>
<li>170 MB</li>
<li>1 event per file</li>
<li>1.4 MB to 2.1 MB each</li>
</ul>
<h3 id="heavy-ion-events">Heavy ion events</h3>
<!--
- from 2018
-->
<ul>
<li>100 files</li>
<li>131 MB</li>
<li>1 event per file</li>
<li>644 KB to 5.5 MB each</li>
</ul>
<!--
## Timing

- Wall time
- Disk $\rightarrow$ RAM **excluded**
- RAM $\rightarrow$ GPU memory **included**
- Fastest from 5 repeats
-->
<h2 id="hardware">Hardware</h2>
<h3 id="hlt-like-machine">HLT-like machine</h3>
<ul>
<li>AMD EPYC 75F3
<ul>
<li>32 cores</li>
<li>max. 4 GHz</li>
<li>256 MB L3 cache</li>
</ul></li>
<li>Nvidia Tesla T4
<ul>
<li>2560 CUDA cores</li>
<li>16 GB GDDR6</li>
<li>8.1 TFLOPS</li>
</ul></li>
</ul>
<h3 id="power9-machine">POWER9 machine</h3>
<ul>
<li>8335-GTH / IBM Power System AC922</li>
<li>IBM POWER9
<ul>
<li>32 cores</li>
<li>max. 4 GHz</li>
<li>320 MB L3 cache</li>
</ul></li>
<li>4 x Nvidia Tesla V100
<ul>
<li>5120 CUDA cores</li>
<li>32 GB HBM2</li>
<li>15.7 TFLOPS</li>
</ul></li>
</ul>
<h1 id="results">Results</h1>
<h2 id="proton-proton-events-1">Proton-proton events</h2>
<p><img src="results/combined-pp.png" style="width:80.0%" /><br />
</p>
<p>* = GPU<br />
** = NX<br />
no star = CPU</p>
<h2 id="heavy-ion-events-1">Heavy ion events</h2>
<p><img src="results/combined-hi.png" style="width:80.0%" /><br />
</p>
<p>* = GPU<br />
** = NX<br />
no star = CPU</p>
<!--
## First simple tests

Note: these were simply run from the command line and timed using the `time` command, so copying from disk to RAM and back is included.

![](results/first.png){ width=80% }
-->
<h1 id="conclusion">Conclusion</h1>
<p>Using the CPU compressor <code>zstd</code> is a reasonable choice with our current hardware and the current state of GPU compressors. <code>dietgpu</code> is promising, and may see significant improvements in the future, as it is in a very early stage in development. <code>dietgpu</code> uses a compression algorithm called Asymmetric Numeral Systems (ANS)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, which is an important part of <code>zstd</code> as well. This looks promising for a future GPU implementation of <code>zstd</code>.</p>
<h1 id="links">Links</h1>
<h2 id="compressors-1">Compressors</h2>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Device</th>
<th style="text-align: left;">Code</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>bsc</code></td>
<td style="text-align: left;">GPU</td>
<td style="text-align: left;"><a href="https://github.com/IlyaGrebnov/libbsc" class="uri">https://github.com/IlyaGrebnov/libbsc</a></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>dietgpu</code></td>
<td style="text-align: left;">GPU</td>
<td style="text-align: left;"><a href="https://github.com/facebookresearch/dietgpu" class="uri">https://github.com/facebookresearch/dietgpu</a></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>libnxz</code></td>
<td style="text-align: left;">IBM NX</td>
<td style="text-align: left;"><a href="https://github.com/libnxz/power-gzip" class="uri">https://github.com/libnxz/power-gzip</a></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>lz4</code></td>
<td style="text-align: left;">CPU</td>
<td style="text-align: left;"><a href="https://github.com/lz4/lz4" class="uri">https://github.com/lz4/lz4</a></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>lzma</code></td>
<td style="text-align: left;">CPU</td>
<td style="text-align: left;"><a href="https://www.7-zip.org/" class="uri">https://www.7-zip.org/</a></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>nvcomp_lz4</code></td>
<td style="text-align: left;">GPU</td>
<td style="text-align: left;"><a href="https://github.com/NVIDIA/nvcomp" class="uri">https://github.com/NVIDIA/nvcomp</a></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>zlib</code></td>
<td style="text-align: left;">CPU</td>
<td style="text-align: left;"><a href="http://zlib.net/" class="uri">http://zlib.net/</a></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>zstd</code></td>
<td style="text-align: left;">CPU</td>
<td style="text-align: left;"><a href="https://github.com/facebook/zstd" class="uri">https://github.com/facebook/zstd</a></td>
</tr>
</tbody>
</table>
<!--
| Name | Device | Code |
|:-----|:-------|:-------|
| `bsc` | GPU | <https://github.com/IlyaGrebnov/libbsc> |
| `culzss` | GPU | <https://github.com/adnanozsoy/CUDA_Compression> |
| `dietgpu` | GPU | <https://github.com/facebookresearch/dietgpu> |
| `hcmc` | GPU | <https://github.com/smadhiv/HuffmanCoding_MPI_CUDA> |
| `libnxz` | IBM NX | <https://github.com/libnxz/power-gzip> |
| `lz4` | CPU | <https://github.com/lz4/lz4> |
| `lzma` | CPU | <https://www.7-zip.org/> |
| `nvcomp_lz4` | GPU | <https://github.com/NVIDIA/nvcomp> |
| `xz` | CPU | <https://tukaani.org/xz/> |
| `zlib` | CPU | <http://zlib.net/> |
| `zstd` | CPU | <https://github.com/facebook/zstd> |
-->
<h2 id="benchmarking-and-plotting">Benchmarking and plotting</h2>
<ul>
<li><code>lzbench</code>, the benchmarking program: <a href="https://github.com/inikep/lzbench" class="uri">https://github.com/inikep/lzbench</a><br />
</li>
<li>our fork of <code>lzbench</code>: <a href="https://github.com/stefanrua/lzbench" class="uri">https://github.com/stefanrua/lzbench</a><br />
</li>
<li><code>gpucomp</code>, the code for the plots and a report: <a href="https://github.com/stefanrua/gpucomp" class="uri">https://github.com/stefanrua/gpucomp</a></li>
</ul>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a href="https://arxiv.org/pdf/1311.2540.pdf" class="uri">https://arxiv.org/pdf/1311.2540.pdf</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
